{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5854eb13",
   "metadata": {},
   "source": [
    "# Fine-Tuning d'un Modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a32f4a6",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95e0716",
   "metadata": {},
   "source": [
    "Dans ce notebook, nous allons effectuer le fine-tuning d'un modèle à partir de l'API Transformers d'Hugging Face. Les étapes suivantes seront suivies :\n",
    "\n",
    "1. Importation des bibliothèques nécessaires.\n",
    "2. Récupération des données.\n",
    "3. Prétraitement des données.\n",
    "4. Récupération du modèle.\n",
    "5. Entraînement du modèle à partir des données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d09d4c8",
   "metadata": {},
   "source": [
    "## Importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8a86a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "import torch\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9504a5d",
   "metadata": {},
   "source": [
    "## Récupération des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161e5835",
   "metadata": {},
   "source": [
    "Pour récupérer un jeu de données sur le Hub, il suffit d'utiliser la fonction `load_dataset` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19afa4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"yelp_review_full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4eafbd",
   "metadata": {},
   "source": [
    "Il s'agit du jeu de données **Yelp Reviews**. Chaque donnée correspond à un avis et une note (1, 2, 3, 4 ou 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44127e05",
   "metadata": {},
   "source": [
    "**Exemple (d'une donnée)** :\n",
    "- Avis : Can't miss stop for the best Fish Sandwich in Pittsburgh.\n",
    "- Note : 5 étoiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aff1d2",
   "metadata": {},
   "source": [
    "Le jeu de données est séparé en deux parties : les données d'**entraînement** et les données de **test**.\n",
    "\n",
    "Ces deux parties sont regroupées dans une sorte de dictionnaire, nommé `DatasetDict` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed381e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 650000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023701eb",
   "metadata": {},
   "source": [
    "Pour accéder à la partie entraînement (respectivement test), on doit mettre entre crochets `\"train\"` (respectivement `\"test\"`) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a4c993b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'text'],\n",
       "    num_rows: 650000\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35d74f6",
   "metadata": {},
   "source": [
    "On obtient ainsi un objet de type `Dataset`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9473fcf7",
   "metadata": {},
   "source": [
    "Pour accéder à une donnée d'un objet de type `Dataset`, il suffit de mettre entre crochets l'indice de la donnée dans le jeu de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e06b3285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 4,\n",
       " 'text': \"Can't miss stop for the best Fish Sandwich in Pittsburgh.\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967f439d",
   "metadata": {},
   "source": [
    "## Prétraitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b8e63",
   "metadata": {},
   "source": [
    "À présent, on doit prétraiter les données pour qu'on puisse par la suite les \"donner à manger\" au modèle.\n",
    "\n",
    "Pour cela, dans notre exemple, on va récupérer le tokenizer pré-entraîné BERT base :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20ccaa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fd885c",
   "metadata": {},
   "source": [
    "On définit ensuite une fonction qui permettra de \"tokénizer\" un \"batch\" de données à partir du tokenizer récupéré :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c0603d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61848c8e",
   "metadata": {},
   "source": [
    "On peut \"tokénizer\" les données du jeu de données avec la méthode `map` de la classe `DatasetDict` ou `Dataset` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c0f1ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae39e8c",
   "metadata": {},
   "source": [
    "Voici un exemple d'une donnée \"tokénizée\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c50033ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_dataset[\"train\"][15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de9e8c6",
   "metadata": {},
   "source": [
    "Il s'agit d'un dictionnaire avec plusieurs caractéristiques :\n",
    "\n",
    "- `label` : le label, ici la note\n",
    "- `text` : le texte avant la \"tokénization\", ici l'avis\n",
    "- `input_ids` : les indices de chaque token\n",
    "- `token_type_ids` : TODO\n",
    "- `attention_mask` : TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351d8bfb",
   "metadata": {},
   "source": [
    "Voici à quoi ressemble la séquence de tokens d'une donnée \"tokénizée\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e298363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.tokenize(tokenizer.decode(tokenized_dataset[\"train\"][15][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ae2796",
   "metadata": {},
   "source": [
    "On peut créer un sous jeu de données du jeu de données initial pour le \"fine-tuning\" afin de réduire le temps qu'il prend :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b43e01bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_dataset[\"train\"].shuffle(seed=42).select(range(100))\n",
    "small_test_dataset = tokenized_dataset[\"test\"].shuffle(seed=42).select(range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b77e02",
   "metadata": {},
   "source": [
    "## Récupération du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6b6fe",
   "metadata": {},
   "source": [
    "Maintenant qu'on s'est occupé des données, on doit récupérer le modèle.\n",
    "\n",
    "Dans notre exemple, la tâche souhaitée est de prédire une note à partir d'un avis. Il s'agit donc d'un apprentissage supervisé (les données d'entraînement sont munis d'une etiquette, ici la note). On peut voir cette tâche comme une classification de textes. On va ainsi récupérer le modèle de classification de textes pré-entraîné BERT base :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2feb4edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=5) # num_labels indique le nombre de labels possibles (i.e. le nombre de classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a191c61",
   "metadata": {},
   "source": [
    "*Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
    "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd9a997",
   "metadata": {},
   "source": [
    "## Entraînement du modèle à partir des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1524616",
   "metadata": {},
   "source": [
    "C'est parti ! On peut \"fine-tune\" le modèle à partir des données !\n",
    "\n",
    "Il y a deux moyens de le faire :\n",
    "\n",
    "- Avec l'API Trainer\n",
    "- Sans l'API Trainer, de manière native avec PyTorch\n",
    "\n",
    "À présent, vous devez choisir un moyen parmi les deux !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a34a3b1",
   "metadata": {},
   "source": [
    "### API Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc10867-93f1-43a2-85cc-438b559c30fc",
   "metadata": {},
   "source": [
    "#### Réglage des hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b65bfd",
   "metadata": {},
   "source": [
    "Il est possible de régler les hyperparamètres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7abb634",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"test_trainer\", eval_strategy=\"epoch\") # eval_strategy=\"epoch\" permet d'afficher l'évaluation de la métrique à la fin de chaque époque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9bb8f1-3d16-43b7-90f6-2669d403ca62",
   "metadata": {},
   "source": [
    "#### Évaluation à partir d'une métrique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b908db05",
   "metadata": {},
   "source": [
    "On a aussi besoin de posséder une métrique permettant de calculer la performance du modèle pendant l'entraînement, ici une simple fonction de précision (entre la prédiction et le label):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f31cc742",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649e608c",
   "metadata": {},
   "source": [
    "On peut alors définir une fonction qui va calculer la précision entre la prédiction et le label :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64f3e557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867a3a68-f2ef-42de-a7d7-d0cb4964d87d",
   "metadata": {},
   "source": [
    "#### Entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8c6fff-38f3-462f-b065-f5e2f05f7764",
   "metadata": {},
   "source": [
    "On crée un objet de type `Trainer` à partir du modèle, du réglage des hyperparamètres, des données d'entraînement et de test, et de la fonction d'évaluation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be63be68-edf0-41e6-93c0-d4e9afa7fe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d989305c-221a-49ff-bc8f-d19543c53247",
   "metadata": {},
   "source": [
    "Cet objet permet d'effectuer l'entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb253a0a-0e6a-4ab0-9316-824df38a8666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.613454</td>\n",
       "      <td>0.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.591599</td>\n",
       "      <td>0.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.584950</td>\n",
       "      <td>0.280000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=39, training_loss=1.5853855426494892, metrics={'train_runtime': 53.6868, 'train_samples_per_second': 5.588, 'train_steps_per_second': 0.726, 'total_flos': 78935442739200.0, 'train_loss': 1.5853855426494892, 'epoch': 3.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9595fe44",
   "metadata": {},
   "source": [
    "### Native avec PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10c98cf-ddba-4fc6-9cad-57ddd8be7119",
   "metadata": {},
   "source": [
    "On doit supprimer la colonne \"text\" et renommer la colonne \"label\" en \"labels\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4318f43b-d5b2-4a84-9484-b3c059130ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = small_train_dataset.remove_columns([\"text\"])\n",
    "small_test_dataset = small_test_dataset.remove_columns([\"text\"])\n",
    "\n",
    "small_train_dataset = small_train_dataset.rename_column(\"label\", \"labels\")\n",
    "small_test_dataset = small_test_dataset.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5283dde7-0fcf-477f-92ef-0909bc1d3169",
   "metadata": {},
   "source": [
    "On modifie le format pour obtenir des tenseurs PyTorch :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "406c4f18-d6c1-4b1a-b0ba-95f43855657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset.set_format(\"torch\")\n",
    "small_test_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c00f78-ac51-4510-bbf9-9e38af448ac8",
   "metadata": {},
   "source": [
    "On crée un objet de type `DataLoader` pour les données d'entraînement et de test afin de pouvoir itérer sur les \"batches\" de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2baf296-164b-4a54-b30d-4a4def043fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=8)\n",
    "test_dataloader = DataLoader(small_test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1d68dd-2706-4a27-ba42-53cc3822d7e0",
   "metadata": {},
   "source": [
    "On récupère un optimiseur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dee82d73-8207-402e-ab44-131b41676cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785b1111-61a1-4a22-84b0-540a2e7dd993",
   "metadata": {},
   "source": [
    "On récupère \"the default learning rate scheduler\" (à partir de `Trainer`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55d9e29d-f498-48f9-a0ea-9a1ebf53b4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1df57b-8891-485d-9567-22a8f6d75980",
   "metadata": {},
   "source": [
    "On essaie si possible d'utiliser comme \"device\" un GPU (pour aller plus vite) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ee5baff-a122-4c23-a884-203b64734227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42c57f3-669f-4673-99f4-09d02f997d03",
   "metadata": {},
   "source": [
    "C'est parti ! On entraîne le modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eec0c037-da3c-43ff-a2a9-8285fbc59c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5bfb461549242d8abd816f3cbb66a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5de52c1-7ea9-496e-9a10-c4f48a6608c6",
   "metadata": {},
   "source": [
    "On finit par évaluer le modèle pour déterminer sa performance :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77a7f7b4-d61a-4693-a577-5453919f1f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.26}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "model.eval()\n",
    "for batch in test_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cea_stage_salome)",
   "language": "python",
   "name": "cea_stage_salome"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
