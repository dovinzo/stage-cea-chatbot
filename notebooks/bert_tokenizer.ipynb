{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df6316d0-3b97-4f94-a4ca-ab4f397f48fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd3a21d9-7d2b-46c5-b0ad-f6cd94fcf6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération du tokenizer pré-entraîné BERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1257e0f-1585-40c4-8aba-f821f03f3120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texte à prétraiter par le tokenizer\n",
    "texte = \"Can I find information about SALOME platform?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08cbaf5-c234-43b3-bc10-412839ab6691",
   "metadata": {},
   "source": [
    "## Utilisation globale pour la tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1ad3ffd-1406-446f-88f1-5e983985fe99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2064, 1045, 2424, 2592, 2055, 9130, 4132, 1029, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# Utilisation globale du tokenizer\n",
    "print(tokenizer(texte))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8673d6f-baee-41d3-a37a-b267298dcb9d",
   "metadata": {},
   "source": [
    "## Séparation des étapes pour la tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6aaaf0be-5351-4a7d-8b78-626e169e22c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['can', 'i', 'find', 'information', 'about', 'facebook', 'platform', '?']\n"
     ]
    }
   ],
   "source": [
    "# Division du texte en tokens\n",
    "tokens = tokenizer.tokenize(texte)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2f02c96-6f97-4a96-8e80-089e1b5b482a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2064, 1045, 2424, 2592, 2055, 16183, 8462, 4132, 1029]\n"
     ]
    }
   ],
   "source": [
    "# Association des tokens à leur ID respectif (définis par le vocabulaire du tokenizer)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b7daead-7853-4ffe-8400-a96469452be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2064, 1045, 2424, 2592, 2055, 16183, 8462, 4132, 1029, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# Ajout des IDs des tokens spéciaux\n",
    "input_ids = tokenizer.prepare_for_model(ids)\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df778d37-a5ad-4112-9421-a1ca4aa7d1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'can', 'i', 'find', 'information', 'about', 'sal', '##ome', 'platform', '?', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Affichage des tokens (avec les tokens spéciaux)\n",
    "print(tokenizer.tokenize(tokenizer.decode(input_ids[\"input_ids\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e218765-62e8-44ba-9971-953e86a5347c",
   "metadata": {},
   "source": [
    "## Décodage avec le tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee86362a-f937-4460-b096-9a6b8010940c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] can i find information about salome platform? [SEP]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98438fd-3b13-4d20-9a06-ff5666bc1768",
   "metadata": {},
   "source": [
    "## Prétraitement de plusieurs textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5548b0d3-34d2-436c-b592-26606101c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sentences = [\n",
    "    \"Can I find information about SALOME platform?\",\n",
    "    \"Where is located CEA Research Center?\",\n",
    "    \"Is it good?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aea35b0-7fcb-40e8-a378-685626689835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 2064, 1045, 2424, 2592, 2055, 16183, 8462, 4132, 1029, 102], [101, 2073, 2003, 2284, 8292, 2050, 2470, 2415, 1029, 102], [101, 2003, 2009, 2204, 1029, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "encoded_inputs = tokenizer(batch_sentences)\n",
    "print(encoded_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2331775d-6946-465b-891e-a92820bfe604",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c30352a-4c30-4878-bf0f-9f7bf0ced2b5",
   "metadata": {},
   "source": [
    "**Padding** is a strategy for ensuring tensors are rectangular by adding a special padding token to shorter sentences :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19649e5b-0ce8-41cd-bce2-74e4468a4eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 2064, 1045, 2424, 2592, 2055, 16183, 8462, 4132, 1029, 102], [101, 2073, 2003, 2284, 8292, 2050, 2470, 2415, 1029, 102, 0], [101, 2003, 2009, 2204, 1029, 102, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]]}\n",
      "\n",
      "\n",
      "['[CLS]', 'can', 'i', 'find', 'information', 'about', 'sal', '##ome', 'platform', '?', '[SEP]']\n",
      "['[CLS]', 'where', 'is', 'located', 'ce', '##a', 'research', 'center', '?', '[SEP]', '[PAD]']\n",
      "['[CLS]', 'is', 'it', 'good', '?', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "encoded_inputs = tokenizer(batch_sentences, padding=True)\n",
    "\n",
    "# Affichage des inputs finaux de chaque phrase\n",
    "print(encoded_inputs)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Affichage des tokens avec le padding\n",
    "print(tokenizer.tokenize(tokenizer.decode(encoded_inputs[\"input_ids\"][0])))\n",
    "print(tokenizer.tokenize(tokenizer.decode(encoded_inputs[\"input_ids\"][1])))\n",
    "print(tokenizer.tokenize(tokenizer.decode(encoded_inputs[\"input_ids\"][2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0551ea-5f66-41b0-bfe3-02fc61656c66",
   "metadata": {},
   "source": [
    "## Truncation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0dac22-4b7a-4f02-84ae-6dd8cde0b1c1",
   "metadata": {},
   "source": [
    "With **truncation**, we can truncate a sequence to the maximum length accepted by the model (if `max_length` not use), or to the maximum length `max_length` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec9a65c7-ba3d-4dd7-9b7c-25dbc64b2a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 2064, 1045, 2424, 102], [101, 2073, 2003, 2284, 102], [101, 2003, 2009, 2204, 102]], 'token_type_ids': [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]}\n",
      "\n",
      "\n",
      "['[CLS]', 'can', 'i', 'find', '[SEP]']\n",
      "['[CLS]', 'where', 'is', 'located', '[SEP]']\n",
      "['[CLS]', 'is', 'it', 'good', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "encoded_inputs = tokenizer(batch_sentences, padding=True, max_length=5, truncation=True)\n",
    "\n",
    "# Affichage des inputs finaux de chaque phrase\n",
    "print(encoded_inputs)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Affichage des tokens avec le padding et la troncation\n",
    "print(tokenizer.tokenize(tokenizer.decode(encoded_inputs[\"input_ids\"][0])))\n",
    "print(tokenizer.tokenize(tokenizer.decode(encoded_inputs[\"input_ids\"][1])))\n",
    "print(tokenizer.tokenize(tokenizer.decode(encoded_inputs[\"input_ids\"][2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67abdd8d-76e0-4d82-ac7a-e610d44c85be",
   "metadata": {},
   "source": [
    "## Construction des tenseurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c714aa3-0267-4a6e-bca8-2387db44e1a6",
   "metadata": {},
   "source": [
    "Pour pouvoir utiliser ces inputs dans un modèle, il faut les placer dans un tenseur. Pour cela, on utilise l'argument `return_tensors` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28cb67e0-c0b3-40ed-bde0-e771223c587f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2064,  1045,  2424,  2592,  2055, 16183,  8462,  4132,  1029,\n",
      "           102],\n",
      "        [  101,  2073,  2003,  2284,  8292,  2050,  2470,  2415,  1029,   102,\n",
      "             0],\n",
      "        [  101,  2003,  2009,  2204,  1029,   102,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "encoded_inputs = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\") # \"pt\" pour PyTorch\n",
    "\n",
    "# Affichage des inputs finaux de chaque phrase\n",
    "print(encoded_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082608cc-6760-427c-b109-75386c3a9e8f",
   "metadata": {},
   "source": [
    "## Décodage avec le tokenizer pour un batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5cd46de-6127-476b-889e-e2c3a4c95d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS] can i find information about salome platform? [SEP]', '[CLS] where is located cea research center? [SEP] [PAD]', '[CLS] is it good? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]']\n"
     ]
    }
   ],
   "source": [
    "# Affichage des tokens avec le padding avec batch_decode\n",
    "print(tokenizer.batch_decode(encoded_inputs[\"input_ids\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stage-cea-chatbot",
   "language": "python",
   "name": "stage-cea-chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
